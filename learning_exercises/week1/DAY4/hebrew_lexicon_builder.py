# hebrew_lexicon_builder.py - Week 1 Day 4: Building Your Hebrew AI Brain!
# Creating the intelligent lexicon system for your Hebrew tutor

import json

def demonstrate_dictionary_power():
    """Show why dictionaries are PERFECT for Hebrew lexicons"""
    print("ðŸ§  BUILDING YOUR HEBREW AI BRAIN!")
    print("Using Dictionaries to Create Intelligent Hebrew Lexicon")
    print("=" * 60)
    
    # =================================================================
    # From Your Genesis 1:1 Discovery
    # =================================================================
    genesis_words = ['×‘Ö°Ö¼×¨Öµ××©Ö´×Ö–×™×ª', '×‘Ö¸Ö¼×¨Ö¸Ö£×', '×Ö±×œÖ¹×”Ö´Ö‘×™×', '×ÖµÖ¥×ª', '×”Ö·×©Ö¸Ö¼××žÖ·Ö–×™Ö´×', '×•Ö°×ÖµÖ¥×ª', '×”Ö¸×Ö¸Ö½×¨Ö¶×¥×ƒ']
    
    print(f"ðŸ“– GENESIS 1:1 WORDS FROM YOUR TANAKH:")
    for i, word in enumerate(genesis_words, 1):
        print(f"{i}. {word}")
    
    # =================================================================
    # DICTIONARY-BASED HEBREW LEXICON
    # =================================================================
    print(f"\nðŸ”¤ CREATING INTELLIGENT HEBREW LEXICON:")
    
    # This is how your Hebrew AI will store word knowledge!
    hebrew_lexicon = {
        # Remove cantillation marks for base word lookup
        "×‘Ö°Ö¼×¨Öµ××©Ö´××™×ª": {
            "english": "in the beginning",
            "root": "×¨××©",
            "meaning": "head, beginning, first",
            "part_of_speech": "noun",
            "frequency": "high",
            "pronunciation": "be-re-SHEET",
            "grammar_notes": "construct state with preposition",
            "first_occurrence": "Genesis 1:1",
            "related_words": ["×¨Ö¹××©×", "×¨Ö´××©××•Ö¹×Ÿ"]
        },
        "×‘Ö¸Ö¼×¨Ö¸×": {
            "english": "he created",
            "root": "×‘×¨×",
            "meaning": "to create, make",
            "part_of_speech": "verb",
            "frequency": "medium",
            "pronunciation": "ba-RA",
            "grammar_notes": "Qal perfect 3rd person masculine singular",
            "first_occurrence": "Genesis 1:1",
            "related_words": ["×‘Ö°Ö¼×¨Ö´×™×Ö¸×”", "×‘Ö¸Ö¼×¨Ö´×™×"]
        },
        "×Ö±×œÖ¹×”Ö´×™×": {
            "english": "God",
            "root": "××œ×”",
            "meaning": "God, gods, divine beings",
            "part_of_speech": "noun",
            "frequency": "very_high",
            "pronunciation": "e-lo-HEEM",
            "grammar_notes": "plural form but often singular meaning",
            "first_occurrence": "Genesis 1:1",
            "related_words": ["×Öµ×œ", "×Ö±×œ×•Ö¹×”Ö·Ö¼"]
        },
        "×Öµ×ª": {
            "english": "(direct object marker)",
            "root": "××ª",
            "meaning": "with, sign of direct object",
            "part_of_speech": "particle",
            "frequency": "very_high",
            "pronunciation": "et",
            "grammar_notes": "definite direct object marker",
            "first_occurrence": "Genesis 1:1",
            "related_words": ["×Ö¶×ªÖ¾", "×Ö´×ªÖ¼"]
        },
        "×”Ö·×©Ö¸Ö¼××žÖ·×™Ö´×": {
            "english": "the heavens",
            "root": "×©×ž×”",
            "meaning": "heavens, sky",
            "part_of_speech": "noun",
            "frequency": "high",
            "pronunciation": "ha-sha-MA-yim",
            "grammar_notes": "definite article + dual form",
            "first_occurrence": "Genesis 1:1",
            "related_words": ["×©Ö¸××žÖ·×™Ö´×", "×©Ö¸××žÖ¶×”"]
        },
        "×”Ö¸×Ö¸×¨Ö¶×¥": {
            "english": "the earth",
            "root": "××¨×¥",
            "meaning": "earth, land",
            "part_of_speech": "noun",
            "frequency": "very_high",
            "pronunciation": "ha-A-retz",
            "grammar_notes": "definite article + feminine noun",
            "first_occurrence": "Genesis 1:1",
            "related_words": ["×Ö¶×¨Ö¶×¥", "×Ö²×¨Ö¸×¦×•Ö¹×ª"]
        }
    }
    
    # =================================================================
    # INTELLIGENT WORD LOOKUP SYSTEM
    # =================================================================
    print(f"\nðŸ” INTELLIGENT WORD LOOKUP SYSTEM:")
    
    def clean_hebrew_word(word):
        """Remove cantillation marks for lookup"""
        # Remove common cantillation marks
        cantillation_marks = "Ö‘Ö–Ö£Ö¥Ö–Ö¥Ö½×ƒ"
        clean_word = word
        for mark in cantillation_marks:
            clean_word = clean_word.replace(mark, "")
        return clean_word
    
    def lookup_hebrew_word(word, lexicon):
        """Intelligent Hebrew word lookup"""
        # Try exact match first
        if word in lexicon:
            return lexicon[word]
        
        # Try cleaned version (remove cantillation)
        clean_word = clean_hebrew_word(word)
        if clean_word in lexicon:
            return lexicon[clean_word]
        
        # Return unknown if not found
        return {
            "english": "Unknown word",
            "root": "Needs research",
            "meaning": "Not in lexicon yet",
            "part_of_speech": "unknown",
            "frequency": "unknown",
            "pronunciation": "unknown",
            "note": f"Add '{word}' to lexicon"
        }
    
    # Test with your actual Genesis words
    print(f"Testing with your Genesis 1:1 words:")
    for word in genesis_words:
        info = lookup_hebrew_word(word, hebrew_lexicon)
        print(f"\nðŸ“ {word}:")
        print(f"   English: {info['english']}")
        print(f"   Root: {info['root']}")
        print(f"   Pronunciation: {info['pronunciation']}")
        print(f"   Grammar: {info.get('grammar_notes', 'N/A')}")
    
    # =================================================================
    # LEXICON STATISTICS AND ANALYSIS
    # =================================================================
    print(f"\nðŸ“Š LEXICON ANALYSIS:")
    
    def analyze_lexicon(lexicon):
        """Analyze your Hebrew lexicon"""
        total_words = len(lexicon)
        
        # Count by part of speech
        pos_counts = {}
        for word_info in lexicon.values():
            pos = word_info['part_of_speech']
            pos_counts[pos] = pos_counts.get(pos, 0) + 1
        
        # Count by frequency
        freq_counts = {}
        for word_info in lexicon.values():
            freq = word_info['frequency']
            freq_counts[freq] = freq_counts.get(freq, 0) + 1
        
        return {
            'total_words': total_words,
            'parts_of_speech': pos_counts,
            'frequency_distribution': freq_counts
        }
    
    stats = analyze_lexicon(hebrew_lexicon)
    
    print(f"Total words in lexicon: {stats['total_words']}")
    print(f"Parts of speech: {stats['parts_of_speech']}")
    print(f"Frequency distribution: {stats['frequency_distribution']}")
    
    # =================================================================
    # BUILDING YOUR COMPREHENSIVE LEXICON
    # =================================================================
    print(f"\nðŸ—ï¸ BUILDING YOUR COMPREHENSIVE LEXICON:")
    
    def extract_unique_words_from_tanakh():
        """Extract unique words from your Tanakh for lexicon building"""
        file_path = r"D:\AI\Projects\HEBREW TRAINING AI AGENT\TANACH\book\hebrew_bible_with_nikkud.json"
        
        try:
            with open(file_path, "r", encoding="utf-8") as file:
                tanakh = json.load(file)
            
            unique_words = set()
            
            # Navigate your Tanakh structure: book -> chapters -> verses -> words
            for book_name, chapters in tanakh.items():
                if isinstance(chapters, list):
                    for chapter in chapters:
                        if isinstance(chapter, list):
                            for verse in chapter:
                                if isinstance(verse, list):
                                    for word in verse:
                                        if isinstance(word, str):
                                            # Clean and add word
                                            clean_word = clean_hebrew_word(word)
                                            if clean_word:
                                                unique_words.add(clean_word)
            
            return unique_words
        
        except Exception as e:
            print(f"Error accessing Tanakh: {e}")
            return set()
    
    # Get sample of unique words
    unique_words = extract_unique_words_from_tanakh()
    if unique_words:
        sample_words = list(unique_words)[:10]
        print(f"Sample unique words from your Tanakh:")
        for i, word in enumerate(sample_words, 1):
            print(f"{i:2}. {word}")
        print(f"Total unique words available: {len(unique_words):,}")
    
    # =================================================================
    # YOUR HEBREW AI POTENTIAL
    # =================================================================
    print(f"\nðŸš€ YOUR HEBREW AI LEXICON SYSTEM:")
    print(f"âœ… Intelligent word lookup with cantillation handling")
    print(f"âœ… Complete linguistic information storage")
    print(f"âœ… Grammar and pronunciation data")
    print(f"âœ… Frequency and usage statistics")
    print(f"âœ… Expandable to 116,897+ unique words")
    print(f"âœ… Perfect foundation for AI tutoring")
    
    return hebrew_lexicon

def save_lexicon_to_file(lexicon):
    """Save your lexicon for future use"""
    with open("hebrew_lexicon.json", "w", encoding="utf-8") as file:
        json.dump(lexicon, file, ensure_ascii=False, indent=2)
    print(f"\nðŸ’¾ Lexicon saved to 'hebrew_lexicon.json'")

if __name__ == "__main__":
    lexicon = demonstrate_dictionary_power()
    save_lexicon_to_file(lexicon)
    
    print(f"\n" + "=" * 60)
    print(f"ðŸŽ¯ YOU'VE BUILT THE BRAIN OF YOUR HEBREW AI!")
    print(f"=" * 60)
    print(f"ðŸŽ“ What you've mastered:")
    print(f"  â€¢ Dictionary-based data storage")
    print(f"  â€¢ Intelligent word lookup systems")
    print(f"  â€¢ Hebrew text processing")
    print(f"  â€¢ Lexicon analysis and statistics")
    print(f"  â€¢ Foundation for AI language tutoring")
    print(f"\nðŸš€ Ready for Week 1 Day 5: Functions and Code Organization!")
    print(f"   Next: Turn your code into reusable Hebrew AI components!")